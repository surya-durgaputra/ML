{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.psychologyinaction.org/psychology-in-action-1/2016/08/13/what-is-a-sampling-distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Non sample method is that of Population census. Here every single unit is measured in the target population. This is easier for smaller target populations but incredibly expensive, difficult or sometimes impossible for larger populations.\n",
    "\n",
    "Hence we depend on population sampling. \n",
    "\n",
    "__Two types of Sampling__\n",
    "### Non - Probability Sampling:\n",
    "- Generally does __not__ involve random selection\n",
    "- Probabilities of selection <u>can't be determined</u> for population units since we have no control over who gets sampled. It is often opportunistic in some way like in examples below and hence can be heavily biased.\n",
    "- Examples:\n",
    "    + __opt in web surveys__ (take whoever is interested in taking that survey. We are not selecting people at random from some well defined list or sampling frame. Its whoever wants to volunteer in that survey and as a result we can't determine the probabilities of selection)  \n",
    "    + __quota sampling__ you try to recruit as many people as you can who fit certain subgroup definition (like African american males or older african american males) until you hit some targets, some number of individuals that you wish to measure. In many cases, researchers try to sample as many inidividuals as they can, not according to any probability scheme, but just on basis of whoever is available and just try to hit their quotas. This is also non-probability sampling as we can't write down the probabilities of a target being selected. We are just trying to meet targets.\n",
    "    + __snowball sampling__ This is a network sampling where a sampled individual refers a friend, who then refers a friend and so on. In this case again, friends are recruiting friends. We don't really have any control over who they recruit or the probabilities with which they are going to recruit these individuals. So snowball sampling is a convenient tool for sampling but as researchers, we have no control over probabilities of selection of those samples.\n",
    "    + __convenience sampling__ Walk down the street and talk to people who are available. Talk to friends or co-workers. Again, no probabilities of selection involved. You are just trying to collect data from individuals who are convenient and in close proximity to you. Again we can't apply probabilities of selection for these individuals and that prevents us from making representative statements about the larger population. It can heavily biased. \n",
    "\n",
    "### Probability Sampling:\n",
    "- Construct list of all units in population = __Sampling Frame__\n",
    "- Determine __probability of selection__ for every unit on the list (known and non-zero)\n",
    "- __Select units from list at random__, with the sampling rates for different subgroups determined by probabilities of selection\n",
    "- Attempt to __measure__ randomly selected units\n",
    "\n",
    "__Why prefer Probability Sampling:__ The known probabilities of selection for all units allow us to make unbiased statements about both population features (the stuff that we are trying to estimate when we analyze the data) and the uncertainity in survey estimates. So in addition to saying that what is the average income of the people, we would also like to say how uncertain we are about those estimates because we are not measuring everyone in the population, we are measuring a sample of individuals. And we want to make an estimate of how uncertain we are with the estimate we are computing.\n",
    "\n",
    "Random selection of population units __protects us against bias from the sample selection mechanism__. \n",
    "\n",
    "__Probability sampling__ allows us to make population __inferences__ about larger populations, based on __sampling distributions__. \n",
    "\n",
    "If we draw a sample from a population, and calculate our estimes from that sample, and we do this process repeatedly, over time, a distribution of estimates emerges. This is called sampling distribution. In reality, we often make only one sample and if the sample drawing was carefully and scientifically designed, we can do representative estimates about larger population from this sample. The big idea is that with careful design, probability samples yield __representative, realistic, random__ samples from larger populations; such samples have statistical properties.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Sampling types:\n",
    "#### Simple Random Sampling (SRS):\n",
    "- Start with know list of N population units, and randomly select n units from the list. So n is the sample size.\n",
    "- Every unit has __equal probability of selection__ = n/N\n",
    "- All possible samples of size n are equally likely.\n",
    "- Estimates of means, proportions and totals based on SRS are __unbiased__ (equal to the population values on average!). Note that for each sample of size n drawn, there might be variability in the estimates, but on average and over a large number of samples, these estimates will be the same as true population estimates.\n",
    "- SRS can be __with replacement__ or __without replacement__\n",
    "    + for both: probability of selection for each unit is still n/N\n",
    "- SRS, though simple, is rarely used in practise. Collecting data from n randomly sampled units in a very large population can be prohibitively expensive. __Exception is when there is relatively cheap data collection based on well-defined population lists or we have a collection of file records where we can literally pull records out of file cabinets.__\n",
    "- SRS is generally done when the populations are smaller and its easier and simpler to collect the data.\n",
    "- SRS connection to __i.i.d. Data__:\n",
    "    + recall that i.i.d. observations are __independent__ and __identically distributed__\n",
    "    + SRS will generate i.i.d. data for a given variable, in theory\n",
    "        - All randomly sampled units will yield observations that are independent( not correlated to eachother) and identically distributed (representative of some larger population of value, again, in theory)\n",
    "\n",
    "Example of SRS:\n",
    "We have a list of 2500 emails received. We need to find the average response time for each email. Here, we cannot just take all 2500 emails because due to infrastructure limitations, to find the response times, we will need to go through each of the email manually. So we do SRS and our sample size is 100.\n",
    "So our sampling design for SRS is: We number emails 1 to 2500 and randomly select 100 using a random number generator.\n",
    "- __Every email has known probability of selection__ = 100/2500\n",
    "- Produces __random, representative sample__ of 100 emails (in theory)\n",
    "- __Estimated mean response time__ will be an __unbiased__ estimate of population mean\n",
    "    + this is a feature of probability sampling - __On average if we were to draw many, many samples of size 100 and compute the mean of each of those, the average of those means will be equal to the true population value.__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Complex Probability Sampling\n",
    "- With larger populations, __complex samples__ often selected, where each sampled unit has known probability of selection. __Complex = anything more complicated than SRS!__\n",
    "- With complex probability sampling, we use very specific features of sampling design that enable us to save on cost and make our samples more efficient.\n",
    "- __Complex samples have certain key features__:\n",
    "    + Population divided into different __strata__, and part of sample is allocated to each __stratum__; this ensures sample representation from each stratum, and reduces variance of survey estimates (__stratification__)\n",
    "    + __Clusters__ of population units (e.g. counties) are randomly sampled first (with known probability) within strata, to save costs of data collection (collect data from cases close to each other geographically). We often use group, strata and cluster interchangeably. In this case, cluster within a stratum is just a multi-level cluster.\n",
    "    + __Units randomly sampled within clusters__, according to some probability of selection and measured\n",
    "- **__So a unit's probability of selection is determined by__**:\n",
    "    + Number of clusters sampled from each stratum\n",
    "    + Total number of clusters in population in each stratum\n",
    "    + Number of units ultimately sampled from each cluster\n",
    "    + Total number of units in population in each cluster\n",
    "\n",
    "Example of finding a unit's probability of selection:\n",
    "- Select **__a__** out of __A__ clusters at random in a given stratum\n",
    "- then select **__b__** out of __B__ units at random from within a selected cluster\n",
    "\n",
    "Probability of selection = $(\\frac{a}{A})(\\frac{b}{B})$\n",
    "The stratum here can be Midwest US. Clusters can be all the counties in the midwest (each county being a cluster). So people designing constraints will decide what a and b will be in accordance to the cost constraints.\n",
    "\n",
    "Example: NHANES\n",
    "- Divide U.S. into different regions based on geography and population density. We refer to these divisions as __strata__ And again, by allocating samples to each of these stratum, we ensure some representation, thus minimizing the risk of a bad simple random sample where when selecting samples totally at random, they just happened to all come from one region. This this approach ensures __increased representation__. \n",
    "- Allocate some number of counties / groups of counties to be sampled from each stratum (These are called __clusters__. We randomly sample clusters again to save costs. This way we can randomly sample households that are within a specific geographic area rather than pure SRS where the households can be from anywhere in US)\n",
    "- Sample certain socio-demographic subgroups of individuals at higher rates within counties. This is called __oversampling__. So maybe, a given project has a certain target sample size for particular subgroups of individuals. We might sample these separate subgroups at higher rates within those counties (or cluster) when we are randomly selecting households. What this leads to is different probabilities of selection for different types of individuals depending on the goals of a project. That oversampling means that different people will have different probabilities of being selected, different rates of selection at that second stage, and that's okay. We still have a probability design and we can make use of those probabilities to ultimately make representative statements about the larger population.\n",
    "\n",
    "__Stage 1__: We have entire US. We can subdivide the US into regions and then sample counties.\n",
    "\n",
    "__Stage 2__: For a county from stage 1, we then randomly choose some areas within a county. This again is a cost saving measure. This is already a multi-stage cluster (stage 1 then stage 2)\n",
    "\n",
    "__Stage 3__: For a particular area within a county from stage 2, we get a list of all the households and do a simple random selection of households.\n",
    "\n",
    "__Stage 4__: At his stage, a field member can actually visit the households from stage 3 and randomly choose a subject within that particular household (like if there are 3 people in a household, randomly choose one). We then take all the measurements from this individual as seen in NHANES dataset.\n",
    "\n",
    "At all four of these stages, we know what the probabilities of selection are. And we maintain those probabilities of selection throughout the entire design. Ultimately we can can compute the probability of being include for every single individual that we might randomly sample.\n",
    "\n",
    "In this type of design, the inverse of a person's probability of selection is then their __sampling weight__. So if my probability is 1/100, my sampling weight is 100. In other words, I represent myself and __99 others__ in the population!\n",
    "\n",
    "This sampling weight, which is a function of probability of selection, is used in the actual data analysis to compute representative population estimates. So that probability of selection plays a direct role in the computation of estimates based on complex samples.\n",
    "\n",
    "So, summarizing, \n",
    "- those weights get used to compute __unbiased estimates__ of population quantities (e.g. mean BMI), accounting for different probabilities of selection.  \n",
    "- Probabilities of selection play a __direct and essential role__ in computation of unbiased population estimates!\n",
    "\n",
    "So __WHY PROBABILITY SAMPLING__:\n",
    "- Having __known, non-zero probability of selection__ for each unit in a population and __subsequent random sampling__ ensures all units will have a chance of being sampled\n",
    "- __Probability sampling__ allows us to compute __unbiased estimates__ (using those sample wieghts), and also estimate features of __sampling distribution__ of estimates that we would see if many of the same types of probability samples were selected. We can actually simulate what that sampling distribution would look like based on selecting only one sample. This is the beauty of probability sampling. We dont have to draw samples over and over again, to get a sense of what that distribution of estimates might look like.\n",
    "\n",
    "Thus, Probability sampling provides a __statistical basis for making inferences__ about certain quantities in larger populations. We can make inferences about the entire population on the basis of just one sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non Probability Samples\n",
    "\n",
    "Features of __non-probability__ samples:\n",
    "- Probabilities of selection __can't be determined__ for sampled units.\n",
    "- __No random selection__ of individual units. So we dont control the random selection mechanism that ultimately yields the sample in a Non-probability sample.\n",
    "- Sample can be divided into groups(strata) or clusters, but __clusters not randomly sampled__ in earlier stages.\n",
    "- Data collection often very cheap relative to probability sampling. This is the big advantage of non-probability samples.\n",
    "\n",
    "Example of Non-probability Sampling:\n",
    "- Study of volunteers (e.g. clinical trials):\n",
    "    + You would often see a flyer or posting online like \"Do you suffer from a disease XXX. If yes, call XXX-XXXX (phone number) and become part of the study\". And then someone calls that number to become part of this study. \n",
    "    + So here, there are no sampling frames or lists. Researchers are just looking for volunteers to join their study. They have no control over who volunteers to join the study.\n",
    "- __Opt-in__/ Intercept web surveys:\n",
    "    + So when you are on a website and you see an invitation to come and complete a survey or you see an opinion survey on a particular website and you decide to join this particular survey.\n",
    "    + Again, there is no probability of selection. There is no random selection. The people trying to collect the data are just looking for volunteers to ultimately join the survey.\n",
    "- __Snowball__ samples:\n",
    "    + "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
