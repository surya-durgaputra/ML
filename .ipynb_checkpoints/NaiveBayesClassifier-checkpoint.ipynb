{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import cross_val_score, KFold, train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop_words : this argument allows us to pass a list of words we do not want to take into account, \n",
    "# such as too frequent words, or words we do not a priori expect to provide information about the \n",
    "# particular topic\n",
    "def get_stop_words():\n",
    "    result = set()\n",
    "    for line in open('stopwords_en.txt', 'r').readlines():\n",
    "        result.add(line.strip())\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_cross_validation(clf,X,y,K):\n",
    "    cv = KFold(len(y),K,shuffle=True, random_state=0)\n",
    "    # by default the score used is the one returned by score method of the estimator (accuracy)\n",
    "    scores = cross_val_score(clf,X,y,cv=cv,scoring='accuracy')\n",
    "    print(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(clf, X_train,X_test,y_train,y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    print(\"Accuracy on training set:\")\n",
    "    print(clf.score(X_train,y_train))\n",
    "    print(\"Accuracy on testing set:\")\n",
    "    print(clf.score(X_test,y_test))\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(\"Classification Report:\")\n",
    "    print(metrics.classification_report(y_test,y_pred))\n",
    "    print(\"Confusion Matrix:\")\n",
    "    print(metrics.confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Pipeline([\n",
    "    ('vect',TfidfVectorizer(\n",
    "            stop_words=get_stop_words(),\n",
    "            token_pattern=r\"\\b[a-z0-9_\\-\\.]+[a-z][a-z0-9_\\-\\.]+\\b\")),\n",
    "    ('clf',MultinomialNB(alpha=0.01))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.91192076 0.91864167 0.91333569 0.9101521  0.91153574]\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model performance using cross validation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "news = fetch_20newsgroups(subset='all')\n",
    "X_train, X_test, y_train, y_test = train_test_split(news.data,news.target, test_size=0.25, random_state=0)\n",
    "len(X_train)\n",
    "evaluate_cross_validation(clf,X_train,y_train,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training set:\n",
      "0.9967454365360124\n",
      "Accuracy on testing set:\n",
      "0.9178692699490663\n",
      "Classification Report:\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.93      0.93       205\n",
      "          1       0.81      0.88      0.84       245\n",
      "          2       0.88      0.82      0.85       250\n",
      "          3       0.76      0.84      0.80       243\n",
      "          4       0.89      0.89      0.89       255\n",
      "          5       0.90      0.90      0.90       240\n",
      "          6       0.89      0.82      0.86       249\n",
      "          7       0.92      0.92      0.92       219\n",
      "          8       0.99      0.96      0.97       246\n",
      "          9       0.97      0.98      0.97       227\n",
      "         10       0.98      0.99      0.98       287\n",
      "         11       0.96      0.98      0.97       234\n",
      "         12       0.91      0.87      0.89       247\n",
      "         13       0.96      0.95      0.95       250\n",
      "         14       0.94      0.96      0.95       240\n",
      "         15       0.92      0.94      0.93       250\n",
      "         16       0.92      0.99      0.96       211\n",
      "         17       0.97      0.99      0.98       246\n",
      "         18       0.96      0.92      0.94       209\n",
      "         19       0.91      0.79      0.84       159\n",
      "\n",
      "avg / total       0.92      0.92      0.92      4712\n",
      "\n",
      "Confusion Matrix:\n",
      "[[190   0   0   0   0   1   0   0   0   0   0   0   0   0   0   6   0   0\n",
      "    0   8]\n",
      " [  0 215  10   5   1   6   2   1   0   0   0   1   1   1   2   0   0   0\n",
      "    0   0]\n",
      " [  0  12 206  21   2   5   3   0   0   0   0   0   1   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   9   7 203  11   3   4   0   0   0   1   0   1   1   2   0   0   1\n",
      "    0   0]\n",
      " [  0   3   4   9 228   1   3   0   0   0   1   1   4   1   0   0   0   0\n",
      "    0   0]\n",
      " [  0  13   3   2   1 216   1   0   2   0   0   0   1   0   1   0   0   0\n",
      "    0   0]\n",
      " [  0   3   0  10   5   0 204   9   0   2   0   4   7   1   2   0   0   1\n",
      "    1   0]\n",
      " [  0   0   1   1   1   2   4 202   0   1   0   0   3   0   0   0   2   0\n",
      "    2   0]\n",
      " [  0   0   0   0   0   1   2   5 236   0   0   0   0   1   0   0   1   0\n",
      "    0   0]\n",
      " [  0   1   0   0   0   0   1   0   1 222   2   0   0   0   0   0   0   0\n",
      "    0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   1 283   0   0   0   0   1   0   0\n",
      "    1   0]\n",
      " [  0   0   0   0   0   1   0   1   0   0   0 230   0   0   0   0   1   0\n",
      "    1   0]\n",
      " [  0   4   1  11   7   1   3   1   0   1   1   1 214   0   2   0   0   0\n",
      "    0   0]\n",
      " [  0   1   1   2   1   0   0   0   0   0   0   0   2 238   4   0   1   0\n",
      "    0   0]\n",
      " [  0   1   0   0   0   1   1   1   0   0   0   0   2   2 231   0   0   1\n",
      "    0   0]\n",
      " [  2   1   1   3   0   1   0   0   0   1   0   0   0   3   0 236   0   0\n",
      "    0   2]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 209   0\n",
      "    1   1]\n",
      " [  1   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0 244\n",
      "    0   0]\n",
      " [  0   1   0   0   0   0   0   0   0   1   0   2   0   0   1   0   7   2\n",
      "  193   2]\n",
      " [ 11   0   0   0   0   0   0   0   0   0   0   0   0   1   0  13   5   2\n",
      "    2 125]]\n"
     ]
    }
   ],
   "source": [
    "# now lets actually test the model and publish report\n",
    "train_and_evaluate(clf,X_train,X_test,y_train,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
